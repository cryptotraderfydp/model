{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib2\n",
    "\n",
    "# connect to poloniex's API\n",
    "url = \"https://poloniex.com/public?command=returnChartData&currencyPair=USDT_BTC&start=1483238867&end=1491014867&period=300\"\n",
    "# parse json returned from the API to Pandas DF\n",
    "openUrl = urllib2.urlopen(url)\n",
    "r = openUrl.read()\n",
    "openUrl.close()\n",
    "d = json.loads(r.decode())\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "original_columns=[u'close', u'date', u'high', u'low', u'open']\n",
    "new_columns = ['Close','Timestamp','High','Low','Open']\n",
    "df = df.loc[:,original_columns]\n",
    "df.columns = new_columns\n",
    "df.to_csv('data/bitcoin2015to2017.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbtime = [['1483238867','1491014867'],['1491014867','1498877267'],['1498877267','1506826067'],['1506826067','1514774867'],['1514774867','1522550867'],['1522550867','1530413267'],['1530413267','1538362067'],['1538362067','1546310867']]\n",
    "ans = []\n",
    "for interval in sbtime:\n",
    "    start, end = interval[0], interval[1]\n",
    "    url = \"https://poloniex.com/public?command=returnChartData&currencyPair=USDT_BTC&start=\"+start+\"&end=\"+end+\"&period=300\"\n",
    "    openUrl = urllib2.urlopen(url)\n",
    "    r = openUrl.read()\n",
    "    openUrl.close()\n",
    "    d = json.loads(r.decode())\n",
    "    df = pd.DataFrame(d)\n",
    "\n",
    "    original_columns=[u'close', u'date', u'high', u'low', u'open']\n",
    "    new_columns = ['Close','Timestamp','High','Low','Open']\n",
    "    df = df.loc[:,original_columns]\n",
    "    df.columns = new_columns\n",
    "    ans.append(df)\n",
    "result = pd.concat(ans)\n",
    "result.to_csv('data/bitcoin2015to2017.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>962.280022</td>\n",
       "      <td>1483238867</td>\n",
       "      <td>962.280022</td>\n",
       "      <td>962.280022</td>\n",
       "      <td>962.280022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962.200000</td>\n",
       "      <td>1483239000</td>\n",
       "      <td>962.200000</td>\n",
       "      <td>962.000000</td>\n",
       "      <td>962.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>963.250005</td>\n",
       "      <td>1483239300</td>\n",
       "      <td>963.250005</td>\n",
       "      <td>962.000000</td>\n",
       "      <td>962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>962.000000</td>\n",
       "      <td>1483239600</td>\n",
       "      <td>962.000000</td>\n",
       "      <td>962.000000</td>\n",
       "      <td>962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>962.000000</td>\n",
       "      <td>1483239900</td>\n",
       "      <td>963.250005</td>\n",
       "      <td>962.000000</td>\n",
       "      <td>963.250005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Close   Timestamp        High         Low        Open\n",
       "0  962.280022  1483238867  962.280022  962.280022  962.280022\n",
       "1  962.200000  1483239000  962.200000  962.000000  962.200000\n",
       "2  963.250005  1483239300  963.250005  962.000000  962.000000\n",
       "3  962.000000  1483239600  962.000000  962.000000  962.000000\n",
       "4  962.000000  1483239900  963.250005  962.000000  963.250005"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "class PastSampler:\n",
    "    '''\n",
    "    Forms training samples for predicting future values from past value\n",
    "    '''\n",
    "     \n",
    "    def __init__(self, N, K, sliding_window = True):\n",
    "        '''\n",
    "        Predict K future sample using N previous samples\n",
    "        '''\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.sliding_window = sliding_window\n",
    " \n",
    "    def transform(self, A):\n",
    "        M = self.N + self.K     #Number of samples per row (sample + target)\n",
    "        #indexes\n",
    "        if self.sliding_window:\n",
    "            I = np.arange(M) + np.arange(A.shape[0] - M + 1).reshape(-1, 1)\n",
    "        else:\n",
    "            if A.shape[0]%M == 0:\n",
    "                I = np.arange(M)+np.arange(0,A.shape[0],M).reshape(-1,1)\n",
    "                \n",
    "            else:\n",
    "                I = np.arange(M)+np.arange(0,A.shape[0] -M,M).reshape(-1,1)\n",
    "            \n",
    "        B = A[I].reshape(-1, M * A.shape[1], A.shape[2])\n",
    "        ci = self.N * A.shape[1]    #Number of features per sample\n",
    "        return B[:, :ci], B[:, ci:] #Sample matrix, Target matrix\n",
    "\n",
    "#data file path\n",
    "dfp = 'data/bitcoin2015to2017.csv'\n",
    "\n",
    "#Columns of price data to use\n",
    "columns = ['Close']\n",
    "df = pd.read_csv(dfp)\n",
    "# df = cnm.loc[:60000,:]\n",
    "time_stamps = df['Timestamp']\n",
    "df = df.loc[:,columns]\n",
    "original_df = pd.read_csv(dfp).loc[:,columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='bitcoin2015to2017_close.h5'\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# normalization\n",
    "for c in columns:\n",
    "    df[c] = scaler.fit_transform(df[c].values.reshape(-1,1))\n",
    "    \n",
    "#Features are input sample dimensions(channels)\n",
    "A = np.array(df)[:,None,:]\n",
    "original_A = np.array(original_df)[:,None,:]\n",
    "time_stamps = np.array(time_stamps)[:,None,None]\n",
    "\n",
    "#Make samples of temporal sequences of pricing data (channel)\n",
    "NPS, NFS = 256, 16         #Number of past and future samples\n",
    "ps = PastSampler(NPS, NFS, sliding_window=False)\n",
    "B, Y = ps.transform(A)\n",
    "input_times, output_times = ps.transform(time_stamps)\n",
    "original_B, original_Y = ps.transform(original_A)\n",
    "\n",
    "import h5py\n",
    "with h5py.File(file_name, 'w') as f:\n",
    "    f.create_dataset(\"inputs\", data = B)\n",
    "    f.create_dataset('outputs', data = Y)\n",
    "    f.create_dataset(\"input_times\", data = input_times)\n",
    "    f.create_dataset('output_times', data = output_times)\n",
    "    f.create_dataset(\"original_datas\", data=np.array(original_df))\n",
    "    f.create_dataset('original_inputs',data=original_B)\n",
    "    f.create_dataset('original_outputs',data=original_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 23:00:27.684565 4556445120 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 617 samples, validate on 155 samples\n",
      "Epoch 1/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0623Epoch 00001: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-01-0.00800.hdf5\n",
      "617/617 [==============================] - 37s 59ms/step - loss: 0.0622 - val_loss: 0.0080\n",
      "Epoch 2/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0273Epoch 00002: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-02-0.00105.hdf5\n",
      "617/617 [==============================] - 35s 57ms/step - loss: 0.0273 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0188Epoch 00003: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-03-0.00015.hdf5\n",
      "617/617 [==============================] - 34s 55ms/step - loss: 0.0188 - val_loss: 1.4732e-04\n",
      "Epoch 4/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0127Epoch 00004: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-04-0.00059.hdf5\n",
      "617/617 [==============================] - 32s 53ms/step - loss: 0.0126 - val_loss: 5.8701e-04\n",
      "Epoch 5/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0096Epoch 00005: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-05-0.00021.hdf5\n",
      "617/617 [==============================] - 32s 53ms/step - loss: 0.0096 - val_loss: 2.1445e-04\n",
      "Epoch 6/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0099Epoch 00006: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-06-0.00050.hdf5\n",
      "617/617 [==============================] - 33s 53ms/step - loss: 0.0099 - val_loss: 4.9751e-04\n",
      "Epoch 7/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0076Epoch 00007: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-07-0.00046.hdf5\n",
      "617/617 [==============================] - 20s 32ms/step - loss: 0.0076 - val_loss: 4.5585e-04\n",
      "Epoch 8/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0073Epoch 00008: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-08-0.00040.hdf5\n",
      "617/617 [==============================] - 15s 24ms/step - loss: 0.0073 - val_loss: 4.0380e-04\n",
      "Epoch 9/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0057Epoch 00009: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-09-0.00007.hdf5\n",
      "617/617 [==============================] - 22s 35ms/step - loss: 0.0057 - val_loss: 6.6569e-05\n",
      "Epoch 10/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0064Epoch 00010: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-10-0.00024.hdf5\n",
      "617/617 [==============================] - 21s 35ms/step - loss: 0.0064 - val_loss: 2.3756e-04\n",
      "Epoch 11/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0062Epoch 00011: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-11-0.00010.hdf5\n",
      "617/617 [==============================] - 18s 29ms/step - loss: 0.0062 - val_loss: 9.8633e-05\n",
      "Epoch 12/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0055Epoch 00012: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-12-0.00015.hdf5\n",
      "617/617 [==============================] - 14s 23ms/step - loss: 0.0055 - val_loss: 1.4829e-04\n",
      "Epoch 13/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0054Epoch 00013: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-13-0.00018.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0054 - val_loss: 1.8492e-04\n",
      "Epoch 14/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0046Epoch 00014: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-14-0.00017.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0046 - val_loss: 1.6599e-04\n",
      "Epoch 15/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0052Epoch 00015: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-15-0.00067.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0052 - val_loss: 6.7025e-04\n",
      "Epoch 16/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0055Epoch 00016: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-16-0.00008.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0055 - val_loss: 8.0697e-05\n",
      "Epoch 17/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0046Epoch 00017: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-17-0.00003.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0046 - val_loss: 3.0488e-05\n",
      "Epoch 18/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00018: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-18-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0041 - val_loss: 1.0528e-05\n",
      "Epoch 19/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0055Epoch 00019: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-19-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0055 - val_loss: 1.0324e-05\n",
      "Epoch 20/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0050Epoch 00020: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-20-0.00006.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0049 - val_loss: 5.7059e-05\n",
      "Epoch 21/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0047Epoch 00021: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-21-0.00009.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0048 - val_loss: 9.1998e-05\n",
      "Epoch 22/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00022: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-22-0.00008.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0045 - val_loss: 8.1714e-05\n",
      "Epoch 23/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0053Epoch 00023: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-23-0.00019.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0053 - val_loss: 1.9240e-04\n",
      "Epoch 24/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00024: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-24-0.00011.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0037 - val_loss: 1.0848e-04\n",
      "Epoch 25/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00025: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-25-0.00020.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0044 - val_loss: 1.9995e-04\n",
      "Epoch 26/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00026: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-26-0.00004.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0045 - val_loss: 3.9982e-05\n",
      "Epoch 27/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00027: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-27-0.00013.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0044 - val_loss: 1.3276e-04\n",
      "Epoch 28/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00028: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-28-0.00002.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0040 - val_loss: 1.9509e-05\n",
      "Epoch 29/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00029: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-29-0.00016.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0040 - val_loss: 1.5875e-04\n",
      "Epoch 30/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00030: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-30-0.00003.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0037 - val_loss: 3.4528e-05\n",
      "Epoch 31/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00031: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-31-0.00013.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0038 - val_loss: 1.3449e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0047Epoch 00032: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-32-0.00007.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0047 - val_loss: 6.9676e-05\n",
      "Epoch 33/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00033: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-33-0.00025.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0039 - val_loss: 2.4612e-04\n",
      "Epoch 34/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00034: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-34-0.00031.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0035 - val_loss: 3.0954e-04\n",
      "Epoch 35/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00035: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-35-0.00006.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0043 - val_loss: 5.7253e-05\n",
      "Epoch 36/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00036: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-36-0.00003.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0035 - val_loss: 2.9521e-05\n",
      "Epoch 37/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00037: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-37-0.00038.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0035 - val_loss: 3.7895e-04\n",
      "Epoch 38/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00038: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-38-0.00010.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0038 - val_loss: 1.0186e-04\n",
      "Epoch 39/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00039: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-39-0.00014.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0038 - val_loss: 1.4253e-04\n",
      "Epoch 40/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00040: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-40-0.00013.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0041 - val_loss: 1.3093e-04\n",
      "Epoch 41/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00041: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-41-0.00007.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0042 - val_loss: 6.5572e-05\n",
      "Epoch 42/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00042: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-42-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0034 - val_loss: 1.0895e-05\n",
      "Epoch 43/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00043: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-43-0.00008.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0037 - val_loss: 8.4730e-05\n",
      "Epoch 44/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00044: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-44-0.00003.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0037 - val_loss: 2.6364e-05\n",
      "Epoch 45/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00045: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-45-0.00011.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0043 - val_loss: 1.1065e-04\n",
      "Epoch 46/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00046: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-46-0.00036.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0035 - val_loss: 3.6301e-04\n",
      "Epoch 47/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00047: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-47-0.00012.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0035 - val_loss: 1.2375e-04\n",
      "Epoch 48/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00048: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-48-0.00013.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0030 - val_loss: 1.3231e-04\n",
      "Epoch 49/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00049: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-49-0.00003.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0034 - val_loss: 2.8493e-05\n",
      "Epoch 50/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00050: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-50-0.00009.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0037 - val_loss: 9.1864e-05\n",
      "Epoch 51/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00051: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-51-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0036 - val_loss: 5.0825e-05\n",
      "Epoch 52/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00052: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-52-0.00009.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0036 - val_loss: 8.6497e-05\n",
      "Epoch 53/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00053: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-53-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0034 - val_loss: 7.1948e-06\n",
      "Epoch 54/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00054: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-54-0.00026.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0032 - val_loss: 2.5759e-04\n",
      "Epoch 55/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00055: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-55-0.00009.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0032 - val_loss: 8.8213e-05\n",
      "Epoch 56/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00056: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-56-0.00011.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0036 - val_loss: 1.0518e-04\n",
      "Epoch 57/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00057: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-57-0.00031.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0035 - val_loss: 3.1470e-04\n",
      "Epoch 58/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00058: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-58-0.00002.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0040 - val_loss: 2.2959e-05\n",
      "Epoch 59/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00059: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-59-0.00008.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0033 - val_loss: 7.6298e-05\n",
      "Epoch 60/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00060: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-60-0.00003.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0031 - val_loss: 3.2838e-05\n",
      "Epoch 61/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00061: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-61-0.00002.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0034 - val_loss: 1.7287e-05\n",
      "Epoch 62/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00062: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-62-0.00002.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0036 - val_loss: 1.7051e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00063: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-63-0.00007.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0034 - val_loss: 7.0069e-05\n",
      "Epoch 64/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00064: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-64-0.00013.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0035 - val_loss: 1.3110e-04\n",
      "Epoch 65/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00065: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-65-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0037 - val_loss: 8.1420e-06\n",
      "Epoch 66/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00066: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-66-0.00008.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0035 - val_loss: 8.1545e-05\n",
      "Epoch 67/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00067: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-67-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0033 - val_loss: 7.2753e-06\n",
      "Epoch 68/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00068: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-68-0.00002.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0037 - val_loss: 2.4669e-05\n",
      "Epoch 69/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00069: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-69-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0038 - val_loss: 6.3411e-06\n",
      "Epoch 70/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00070: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-70-0.00008.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0041 - val_loss: 8.1773e-05\n",
      "Epoch 71/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00071: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-71-0.00004.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0033 - val_loss: 4.2194e-05\n",
      "Epoch 72/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00072: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-72-0.00011.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0031 - val_loss: 1.0997e-04\n",
      "Epoch 73/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00073: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-73-0.00003.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0031 - val_loss: 2.5098e-05\n",
      "Epoch 74/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00074: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-74-0.00011.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0035 - val_loss: 1.0686e-04\n",
      "Epoch 75/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00075: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-75-0.00004.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0036 - val_loss: 4.1701e-05\n",
      "Epoch 76/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00076: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-76-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0035 - val_loss: 4.7544e-05\n",
      "Epoch 77/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00077: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-77-0.00023.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0032 - val_loss: 2.2646e-04\n",
      "Epoch 78/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00078: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-78-0.00006.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0033 - val_loss: 6.0427e-05\n",
      "Epoch 79/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00079: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-79-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0031 - val_loss: 4.8876e-05\n",
      "Epoch 80/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00080: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-80-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0028 - val_loss: 5.0487e-05\n",
      "Epoch 81/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00081: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-81-0.00008.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0034 - val_loss: 7.5326e-05\n",
      "Epoch 82/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00082: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-82-0.00006.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0037 - val_loss: 5.9861e-05\n",
      "Epoch 83/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00083: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-83-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0034 - val_loss: 4.9088e-05\n",
      "Epoch 84/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00084: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-84-0.00018.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0036 - val_loss: 1.7546e-04\n",
      "Epoch 85/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00085: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-85-0.00016.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0029 - val_loss: 1.6488e-04\n",
      "Epoch 86/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00086: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-86-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0033 - val_loss: 9.0105e-06\n",
      "Epoch 87/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00087: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-87-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0028 - val_loss: 5.8790e-06\n",
      "Epoch 88/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00088: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-88-0.00010.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0030 - val_loss: 9.9229e-05\n",
      "Epoch 89/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00089: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-89-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0037 - val_loss: 4.8659e-05\n",
      "Epoch 90/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00090: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-90-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0036 - val_loss: 9.3362e-06\n",
      "Epoch 91/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00091: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-91-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0029 - val_loss: 5.4537e-05\n",
      "Epoch 92/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00092: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-92-0.00016.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0032 - val_loss: 1.5907e-04\n",
      "Epoch 93/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00093: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-93-0.00002.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0042 - val_loss: 1.7697e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00094: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-94-0.00006.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0037 - val_loss: 6.2232e-05\n",
      "Epoch 95/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00095: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-95-0.00011.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0045 - val_loss: 1.0592e-04\n",
      "Epoch 96/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00096: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-96-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0030 - val_loss: 5.3439e-06\n",
      "Epoch 97/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00097: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-97-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0039 - val_loss: 7.7661e-06\n",
      "Epoch 98/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00098: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-98-0.00001.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0035 - val_loss: 7.8138e-06\n",
      "Epoch 99/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00099: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-99-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 19ms/step - loss: 0.0036 - val_loss: 5.0078e-05\n",
      "Epoch 100/100\n",
      "616/617 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00100: saving model to weights/bitcoin2015to2017_close_LSTM_1_tanh_leaky_-100-0.00005.hdf5\n",
      "617/617 [==============================] - 12s 20ms/step - loss: 0.0032 - val_loss: 5.1465e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x141256e50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Reshape\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM, LeakyReLU\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "import h5py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "with h5py.File(''.join(['bitcoin2015to2017_close.h5']), 'r') as hf:\n",
    "    datas = hf['inputs'].value\n",
    "    labels = hf['outputs'].value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "step_size = datas.shape[1]\n",
    "units= 50\n",
    "second_units = 30\n",
    "batch_size = 8\n",
    "nb_features = datas.shape[2]\n",
    "epochs = 100\n",
    "output_size=16\n",
    "output_file_name='bitcoin2015to2017_close_LSTM_1_tanh_leaky_'\n",
    "#split training validation\n",
    "training_size = int(0.8* datas.shape[0])\n",
    "training_datas = datas[:training_size,:]\n",
    "training_labels = labels[:training_size,:,0]\n",
    "validation_datas = datas[training_size:,:]\n",
    "validation_labels = labels[training_size:,:,0]\n",
    "\n",
    "\n",
    "#build model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=units,activation='tanh', input_shape=(step_size,nb_features),return_sequences=False))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(output_size))\n",
    "model.add(LeakyReLU())\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(training_datas, training_labels, batch_size=batch_size,validation_data=(validation_datas,validation_labels), epochs = epochs, callbacks=[CSVLogger(output_file_name+'.csv', append=True),ModelCheckpoint('weights/'+output_file_name+'-{epoch:02d}-{val_loss:.5f}.hdf5', monitor='val_loss', verbose=1,mode='min')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
